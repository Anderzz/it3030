{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stacked_mnist import *\n",
    "from verification_net import VerificationNet\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from autoencoder import Autoencoder\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 15\n",
    "NUM_CHANNELS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StackedMNISTData(mode=DataMode.COLOR_BINARY_COMPLETE)\n",
    "\n",
    "train_dataset = data.get_full_data_set(training=True)\n",
    "test_dataset = data.get_full_data_set(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedMnistDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = torch.from_numpy(data[0]).float()\n",
    "        self.y = torch.from_numpy(data[1]).float()\n",
    "        # turn them into long tensors\n",
    "        self.y = self.y.long()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_mnist_train = StackedMnistDataset(train_dataset)\n",
    "stacked_mnist_test = StackedMnistDataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(stacked_mnist_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(stacked_mnist_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 28, 28, 3])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    # reshape to (batch_size, num_channels, height, width)\n",
    "    #x = x.reshape(-1, 3, 28, 28)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa50eaa2d30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(next(iter(train_loader))[0][3])\n",
    "plt.imshow(next(iter(train_loader))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "model = Autoencoder\n",
    "criterion = nn.BCELoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=EPOCHS, force_retrain=False):\n",
    "\n",
    "    # try to load the model if it exists and force_retrain is False\n",
    "    if not force_retrain:\n",
    "        try:\n",
    "            checkpoint = torch.load(\"./models/stacked_gen_autoencoder.pth\")\n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            start_epoch = checkpoint[\"epoch\"] + 1\n",
    "            print(\"Loaded checkpoint from epoch\", start_epoch)\n",
    "        except:\n",
    "            start_epoch = 0\n",
    "            print(\"Starting from scratch\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        print(\"Starting from scratch (forced retrain)\")\n",
    "\n",
    "    # train the model\n",
    "    outputs = []\n",
    "    model.train()\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        for im, _ in train_loader:\n",
    "            num_channels = im.shape[-1]\n",
    "            im = im.reshape(-1, num_channels, 28, 28)\n",
    "            im = im.to(device)\n",
    "            # ===================forward=====================\n",
    "            output = model(im)\n",
    "            output = output.squeeze().reshape(-1, num_channels, 28, 28)\n",
    "            loss = criterion(output, im)\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, EPOCHS, loss.item()))\n",
    "        outputs.append((epoch, im, output))\n",
    "\n",
    "    # save the model\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, \"./models/stacked_gen_autoencoder.pth\")\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "train_outputs = train(epochs=EPOCHS, force_retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(train_outputs[0][1][3].reshape(28, 28, 3).detach().cpu().numpy())\n",
    "imgs = train_outputs[0][1].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "recon = train_outputs[80][2].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "# plot them in a subplot\n",
    "fig, axs = plt.subplots(2, 10, figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    axs[0, i].imshow(imgs[i])\n",
    "    axs[1, i].imshow(recon[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_outputs:\n",
    "    # ensure 10 iterations\n",
    "    desired_iterations = 10\n",
    "    num_train_outputs = len(train_outputs)\n",
    "    step = max(num_train_outputs // desired_iterations, 1)\n",
    "    \n",
    "    for k in range(0, EPOCHS, step):\n",
    "        plt.figure(figsize=(9, 2))\n",
    "        plt.gray()\n",
    "\n",
    "        imgs = train_outputs[k][1].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "        recon = train_outputs[k][2].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "\n",
    "        for i, item in enumerate(imgs):\n",
    "            if i >= 9:\n",
    "                break\n",
    "            plt.subplot(2, 9, i + 1)\n",
    "            plt.imshow(item[0])\n",
    "\n",
    "        for i, item in enumerate(recon):\n",
    "            if i >= 9:\n",
    "                break\n",
    "            plt.subplot(2, 9, 9 + i + 1)\n",
    "            plt.imshow(item[0])\n",
    "\n",
    "        plt.suptitle(f\"Epoch {k}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_outputs:\n",
    "    for k in range(0, EPOCHS, 4):\n",
    "        plt.figure(figsize=(9, 2))\n",
    "        #plt.gray()\n",
    "\n",
    "        imgs = train_outputs[k][1].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "        print(imgs.shape)\n",
    "        recon = train_outputs[k][2].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "\n",
    "        for i, item in enumerate(imgs):\n",
    "            if i >= 9:\n",
    "                break\n",
    "            plt.subplot(2, 9, i + 1)\n",
    "            plt.imshow(item[0])\n",
    "\n",
    "        for i, item in enumerate(recon):\n",
    "            if i >= 9:\n",
    "                break\n",
    "            plt.subplot(2, 9, 9 + i + 1)\n",
    "            plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the test set\n",
    "test_outputs, test_labels = generate_test_images(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "print(test_labels[k])\n",
    "plt.imshow(test_outputs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_net = VerificationNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictability, accuracy = verification_net.check_predictability(test_outputs, test_labels, tolerance=0.5)\n",
    "coverage = verification_net.check_class_coverage(test_outputs, tolerance=0.5)\n",
    "print(f\"Predictability: {predictability} \\nAccuracy: {accuracy} \\nCoverage: {coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder = model.decoder\n",
    "# num_samples = 36\n",
    "# z = np.random.rand(num_samples, 16)\n",
    "\n",
    "# generative_out = decoder(torch.from_numpy(z).float().to(device)).reshape(-1, 28, 28, 1).detach().cpu().numpy()\n",
    "# generative_out_tile = generative_out.squeeze()\n",
    "# tiled_image = tile_images(generative_out_tile, show=True)\n",
    "\n",
    "# generative_predictability, generative_accuracy = verification_net.check_predictability(generative_out, tolerance=0.8)\n",
    "# generative_coverage = verification_net.check_class_coverage(generative_out, tolerance=0.8)\n",
    "# print(f\"Predictability: {generative_predictability} \\nAccuracy: {generative_accuracy} \\nCoverage: {generative_coverage}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
