{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stacked_mnist import *\n",
    "from verification_net import VerificationNet\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from autoencoder import Autoencoder\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 15\n",
    "NUM_CHANNELS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StackedMNISTData(mode=DataMode.COLOR_BINARY_COMPLETE)\n",
    "\n",
    "train_dataset = data.get_full_data_set(training=True)\n",
    "test_dataset = data.get_full_data_set(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedMnistDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = torch.from_numpy(data[0]).float()\n",
    "        self.y = torch.from_numpy(data[1]).float()\n",
    "        # turn them into long tensors\n",
    "        self.y = self.y.long()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_mnist_train = StackedMnistDataset(train_dataset)\n",
    "stacked_mnist_test = StackedMnistDataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(stacked_mnist_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(stacked_mnist_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 28, 28, 3])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    # reshape to (batch_size, num_channels, height, width)\n",
    "    #x = x.reshape(-1, 3, 28, 28)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f47c9cfeca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(next(iter(train_loader))[0][3])\n",
    "plt.imshow(next(iter(train_loader))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.2)\n",
       "    (13): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Unflatten(dim=1, unflattened_size=(64, 1, 1))\n",
       "    (7): ConvTranspose2d(64, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.2)\n",
       "    (10): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.2)\n",
       "    (13): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (14): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "model = Autoencoder(task=\"generate\")\n",
    "criterion = nn.BCELoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=EPOCHS, force_retrain=False):\n",
    "\n",
    "    # try to load the model if it exists and force_retrain is False\n",
    "    if not force_retrain:\n",
    "        try:\n",
    "            checkpoint = torch.load(\"./models/stacked_gen_autoencoder.pth\")\n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            start_epoch = checkpoint[\"epoch\"] + 1\n",
    "            print(\"Loaded checkpoint from epoch\", start_epoch)\n",
    "        except:\n",
    "            start_epoch = 0\n",
    "            print(\"Starting from scratch\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        print(\"Starting from scratch (forced retrain)\")\n",
    "\n",
    "    # train the model\n",
    "    outputs = []\n",
    "    model.train()\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        for im, _ in train_loader:\n",
    "            num_channels = im.shape[-1]\n",
    "            im = im.reshape(-1, num_channels, 28, 28)\n",
    "            im = im.to(device)\n",
    "            # ===================forward=====================\n",
    "            output = model(im)\n",
    "            output = output.squeeze().reshape(-1, num_channels, 28, 28)\n",
    "            loss = criterion(output, im)\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, EPOCHS, loss.item()))\n",
    "        outputs.append((epoch, im, output))\n",
    "\n",
    "        # save the model\n",
    "        if outputs:\n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(checkpoint, \"./models/stacked_gen_autoencoder.pth\")\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 30\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "train_outputs = train(epochs=EPOCHS, force_retrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_outputs:\n",
    "    # ensure 10 iterations\n",
    "    desired_iterations = 10\n",
    "    num_train_outputs = len(train_outputs)\n",
    "    step = max(num_train_outputs // desired_iterations, 1)\n",
    "    \n",
    "    for k in range(0, EPOCHS, step):\n",
    "        plt.figure(figsize=(9, 2))\n",
    "        plt.gray()\n",
    "\n",
    "        imgs = train_outputs[k][1].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "        recon = train_outputs[k][2].reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "\n",
    "        for i, item in enumerate(imgs):\n",
    "            if i >= 9:\n",
    "                break\n",
    "            plt.subplot(2, 9, i + 1)\n",
    "            plt.imshow(item)\n",
    "\n",
    "        for i, item in enumerate(recon):\n",
    "            if i >= 9:\n",
    "                break\n",
    "            plt.subplot(2, 9, 9 + i + 1)\n",
    "            plt.imshow(item)\n",
    "\n",
    "        plt.suptitle(f\"Epoch {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the test set\n",
    "test_outputs, test_labels = generate_test_images(model, test_loader, device)\n",
    "test_outputs, test_labels = test_outputs.cpu().numpy(), test_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 3)\n",
      "275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f47c9ed7760>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 22\n",
    "test_im = test_outputs[k].reshape(1, 28, 28, 3)\n",
    "print(test_im.shape)\n",
    "print(test_labels[k])\n",
    "plt.imshow(test_outputs[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_net = VerificationNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictability: 0.0309 \n",
      "Accuracy: 0.0038 \n",
      "Coverage: 0.041\n"
     ]
    }
   ],
   "source": [
    "predictability, accuracy = verification_net.check_predictability(test_outputs, test_labels, tolerance=0.5)\n",
    "coverage = verification_net.check_class_coverage(test_outputs, tolerance=0.5)\n",
    "print(f\"Predictability: {predictability} \\nAccuracy: {accuracy} \\nCoverage: {coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 28, 28, 3]' is invalid for input of size 7840",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-be653f978dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgenerative_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerative_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgenerative_out_tile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerative_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 28, 28, 3]' is invalid for input of size 7840"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    num_samples = 10\n",
    "    # z = np.random.rand(num_samples, 16)\n",
    "    z = torch.rand(num_samples, 16).to(device)\n",
    "    print(z.shape)\n",
    "    generative_out = model.decoder(z).to(device).reshape(-1, 28, 28, 3).detach().cpu().numpy()\n",
    "    print(generative_out.shape)\n",
    "    generative_out_tile = generative_out.squeeze()\n",
    "    tiled_image = tile_images(generative_out_tile, show=True)\n",
    "\n",
    "    generative_predictability, generative_accuracy = verification_net.check_predictability(generative_out, tolerance=0.5)\n",
    "    generative_coverage = verification_net.check_class_coverage(generative_out, tolerance=0.5)\n",
    "    print(f\"Predictability: {generative_predictability} \\nAccuracy: {generative_accuracy} \\nCoverage: {generative_coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.2)\n",
       "  (3): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): LeakyReLU(negative_slope=0.2)\n",
       "  (6): Unflatten(dim=1, unflattened_size=(64, 1, 1))\n",
       "  (7): ConvTranspose2d(64, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): LeakyReLU(negative_slope=0.2)\n",
       "  (10): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): LeakyReLU(negative_slope=0.2)\n",
       "  (13): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (14): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
